{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spell_checker.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Coder-Nikita/spell_checker/blob/master/spell_checker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6jQ1d7w68AkZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CaHL10WCuCQx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**downloading dataset : google's one billion corpus**"
      ]
    },
    {
      "metadata": {
        "id": "aoFy4Sb30CI2",
        "colab_type": "code",
        "outputId": "daf1afd2-97dd-4702-a4cf-cba69645855f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://www.statmt.org/lm-benchmark/1-billion-word-language-modeling-benchmark-r13output.tar.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-10 10:21:11--  http://www.statmt.org/lm-benchmark/1-billion-word-language-modeling-benchmark-r13output.tar.gz\n",
            "Resolving www.statmt.org (www.statmt.org)... 129.215.197.184\n",
            "Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1792209805 (1.7G) [application/x-gzip]\n",
            "Saving to: ‘1-billion-word-language-modeling-benchmark-r13output.tar.gz’\n",
            "\n",
            "1-billion-word-lang 100%[===================>]   1.67G   312KB/s    in 72m 37s \n",
            "\n",
            "2019-04-10 11:33:48 (402 KB/s) - ‘1-billion-word-language-modeling-benchmark-r13output.tar.gz’ saved [1792209805/1792209805]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XiFzqe9SueiI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**unzipping .tar.gz file**"
      ]
    },
    {
      "metadata": {
        "id": "BDh7ajqI6s85",
        "colab_type": "code",
        "outputId": "eeeeee67-d178-4170-9eca-f5053dc89474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3230
        }
      },
      "cell_type": "code",
      "source": [
        "!tar -zxvf 1-billion-word-language-modeling-benchmark-r13output.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-billion-word-language-modeling-benchmark-r13output/\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00024-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00057-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00055-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00096-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00081-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00033-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00072-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00082-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00018-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00008-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00059-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00005-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00091-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00062-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00031-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00095-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00076-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00006-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00038-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00015-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00087-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00021-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00049-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00009-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00027-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00056-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00046-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00032-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00029-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00088-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00085-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00011-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00012-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00067-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00003-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00093-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00050-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00053-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00044-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00019-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00066-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00028-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00045-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00039-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00071-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00052-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00078-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00037-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00002-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00014-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00048-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00017-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00004-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00077-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00080-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00020-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00051-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00016-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00079-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00043-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00068-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00099-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00064-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00034-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00054-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00040-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00070-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00063-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00041-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00083-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00061-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00073-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00094-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00030-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00060-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00035-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00023-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00042-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00025-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00090-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00089-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00065-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00075-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00022-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00026-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00098-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00084-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00010-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00069-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00013-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00092-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00036-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00097-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00007-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00074-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00001-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00047-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00086-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00058-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/tmp/\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/de/\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/de/de102cd0c91cd19e6612f0840e68a2f20ba8134c.svn-base\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/de/deed1b75d3bd5cc36ae6aeb85d56680b892b7948.svn-base\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/86/\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/86/86c58db52fbf362c5bc329afc33b8805085fcb0d.svn-base\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/9f/\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/9f/9f2882e21f860a83ad6ea8898ebab140974ed301.svn-base\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/bc/\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/bc/bcdbc523ee7488dc438cab869b6d5e236578dbfa.svn-base\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/d2/\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/d2/d2718bc26d0ee0a213d7d4add99a304cb5b39ede.svn-base\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/c5/\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/c5/c5b24f61479da923123d0394a188da922ea0359c.svn-base\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/11/\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/11/116d6ea61730d8199127596b072e981338597779.svn-base\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/b0/\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/b0/b0e26559cfe641245584a9400b35ba28d64f1411.svn-base\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/d3/\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/d3/d3ae508e3bcb0e696dd70aecd052410f1f7afc1d.svn-base\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/9e/\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/9e/9e148bd766e8805e0eb97eeae250433ec7a2e996.svn-base\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/31/\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/31/31b645a482e0b81fda3c567cada307c6fcf7ec80.svn-base\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/da/\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/da/da39a3ee5e6b4b0d3255bfef95601890afd80709.svn-base\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/c1/\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/c1/c1ed42c415ec884e591fb5c70d373da640a383b5.svn-base\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/e3/\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/pristine/e3/e37ba0f85e94073ccaced1eed7e4f5d737a25f49.svn-base\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/entries\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/format\n",
            "1-billion-word-language-modeling-benchmark-r13output/.svn/wc.db\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00015-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00031-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00027-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00010-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00033-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00042-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00046-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00037-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00029-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00013-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00002-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00048-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00006-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00030-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00025-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00039-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00008-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00020-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00001-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00034-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00044-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00045-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00016-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00004-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00035-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00038-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00009-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00024-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00022-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00021-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00032-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00011-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00049-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00041-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00019-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00023-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00040-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00014-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00007-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00017-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00012-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00018-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00003-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00028-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en-00000-of-00100\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00043-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00005-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00036-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00026-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en.heldout-00047-of-00050\n",
            "1-billion-word-language-modeling-benchmark-r13output/README\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FLjVu5PXsXqk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **loading the data**"
      ]
    },
    {
      "metadata": {
        "id": "rgYSzoF5IA2c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_file(path):\n",
        "    \"\"\"Load a text file from corpus\"\"\"\n",
        "    input_file = os.path.join(path)\n",
        "    with open(input_file) as f:\n",
        "        text = f.read()\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cUQ2oqPqDYkk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = '1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/'\n",
        "train_files = [f for f in listdir(path) if isfile(join(path, f))]\n",
        "train_files = train_files[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eS9x5-ptIPmd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "for text in train_files:\n",
        "    texts.append(load_file(path+text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wqP-tE_LJlhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8dc04968-cf18-4e2f-8055-df0668988108"
      },
      "cell_type": "code",
      "source": [
        "texts[0][:500]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Already German dairy manufacturers Milram have said they are considering their options as the already battered image of cycling takes another blow .\\nQuoting \" people familiar with the situation , \" Saturday \\'s Wall Street Journal said discussions involving large MGM Mirage bondholders such as activist investor Carl Icahn and private-equity fund Oaktree Capital Management are focusing on having the Las Vegas firm file for Chapter 11 bankruptcy protection and then pumping in new capital .\\nParadoxi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "9MW9_LOste7E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **preparing data**"
      ]
    },
    {
      "metadata": {
        "id": "sebPqM3wy0sx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9ef02705-d85c-4982-95a4-1f5b6ab54d2f"
      },
      "cell_type": "code",
      "source": [
        "import utils\n",
        "\n",
        "# get list of words\n",
        "words = utils.preprocess(text)\n",
        "print(words[:30])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['as', 'well', 'as', 'funding', 'equipment', '<COMMA>', 'the', 'foundation', 'has', 'paid', 'for', 'the', 'salary', 'of', 'a', 'full-time', 'nurse', 'and', 'doctor', 'over', 'the', 'next', 'three', 'years', '<PERIOD>', 'the', 'alert', 'among', 'you', 'will']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7o2SfV6jy2w8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bd94cdd1-6540-4b55-b47d-3c67f5866bf4"
      },
      "cell_type": "code",
      "source": [
        "print(\"Total words in text: {}\".format(len(words)))\n",
        "print(\"Unique words: {}\".format(len(set(words))))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total words in text: 7682879\n",
            "Unique words: 36283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GrwK9f1nO1QD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# a dictionary to convert the vocabulary to integers\n",
        "vocab_to_int = {}\n",
        "count = 0\n",
        "for text in texts:\n",
        "    for character in text:\n",
        "        if character not in vocab_to_int:\n",
        "            vocab_to_int[character] = count\n",
        "            count += 1\n",
        "\n",
        "# Add special tokens to vocab_to_int\n",
        "codes = ['<PAD>','<EOS>','<GO>']\n",
        "for code in codes:\n",
        "    vocab_to_int[code] = count\n",
        "    count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O4JT-R2rP1dP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "af2ad4b5-2025-42c5-d0c6-78dda2ce13bc"
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab_to_int)\n",
        "print(\"The vocabulary contains {} characters.\".format(vocab_size))\n",
        "print(sorted(vocab_to_int))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The vocabulary contains 946 characters.\n",
            "['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '<EOS>', '<GO>', '<PAD>', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '\\x80', '\\x83', '\\x88', '\\x8a', '\\x8c', '\\x8e', '\\x91', '\\x92', '\\x93', '\\x94', '\\x95', '\\x96', '\\x97', '\\x99', '\\x9a', '\\x9c', '\\x9d', '\\x9e', '¡', '¢', '£', '¤', '¥', '¦', '§', '¨', '©', 'ª', '«', '¬', '®', '¯', '°', '±', '²', '³', '´', 'µ', '¶', '·', '¸', '¹', 'º', '»', '¼', '½', '¾', '¿', 'À', 'Á', 'Â', 'Ã', 'Ä', 'Å', 'Æ', 'Ç', 'È', 'É', 'Ê', 'Ë', 'Ì', 'Í', 'Î', 'Ï', 'Ð', 'Ñ', 'Ò', 'Ó', 'Ô', 'Õ', 'Ö', '×', 'Ø', 'Ù', 'Ú', 'Û', 'Ü', 'Ý', 'Þ', 'ß', 'à', 'á', 'â', 'ã', 'ä', 'å', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ð', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ö', '÷', 'ø', 'ù', 'ú', 'û', 'ü', 'ý', 'þ', 'ÿ', 'ā', 'ă', 'ą', 'ć', 'ĉ', 'Č', 'č', 'đ', 'ē', 'ĕ', 'ė', 'ę', 'ě', 'ĝ', 'ğ', 'ī', 'İ', 'ı', 'Ł', 'ł', 'ń', 'ņ', 'Ň', 'ō', 'œ', 'ř', 'Ś', 'ś', 'Ş', 'ş', 'Š', 'š', 'ũ', 'ů', 'ű', 'ŵ', 'ŷ', 'Ÿ', 'ź', 'Ż', 'ż', 'Ž', 'ž', 'ƒ', 'ơ', 'ư', 'ǧ', 'ə', 'ʒ', 'ʻ', 'ʼ', 'ʽ', 'ˆ', 'ˇ', 'ˈ', 'ː', '˘', '˚', '˛', '˜', 'Γ', 'Θ', 'Σ', 'Φ', 'Ω', 'ά', 'ί', 'α', 'β', 'δ', 'ε', 'η', 'θ', 'ι', 'κ', 'λ', 'μ', 'ν', 'ο', 'π', 'ρ', 'ς', 'σ', 'τ', 'ϋ', 'ό', 'ύ', 'Є', 'А', 'В', 'Г', 'Е', 'К', 'Л', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'Я', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'х', 'ц', 'ч', 'ш', 'щ', 'ы', 'ь', 'ю', 'я', 'ё', 'Ұ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ح', 'خ', 'د', 'ر', 'ز', 'س', 'ش', 'ض', 'ع', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ي', 'چ', 'گ', 'ی', 'ạ', 'ả', 'ấ', 'ị', 'ỏ', 'ữ', 'ự', 'Ἁ', 'Ἡ', 'ἱ', 'ᾱ', '\\u200b', '\\u200e', '\\u200f', '‐', '‑', '―', '‗', '‚', '‟', '†', '‡', '•', '\\u202a', '\\u202b', '\\u202c', '′', '‹', '›', '⁄', '⁈', '₀', '₁', '₂', '₤', '€', '⃜', '№', '™', '⅓', '⅔', '⅛', '⅝', '←', '↑', '→', '∂', '∆', '∈', '−', '√', '∞', '∧', '∨', '∫', '≇', '≈', '≠', '≥', '⋅', '④', '─', '▁', '▂', '▃', '▄', '▅', '▆', '▇', '█', '▉', '▊', '▋', '▌', '■', '●', '☂', '☃', '★', '☆', '☑', '♠', '♣', '♥', '♦', '♪', '♫', '✈', '✤', '✭', '❤', '\\u2fff', '、', '。', 'あ', 'い', 'え', 'じ', 'で', 'な', 'ゃ', '㠠', '㠭', '㡢', '㡮', '㤮', '㤵', '㧡', '㧯', '㧵', '㨬', '㨱', '㨲', '㩠', '㩢', '㩣', '㩤', '㩥', '㩬', '㩭', '㩮', '㩶', '㭡', '㮴', '一', '三', '上', '下', '不', '世', '个', '中', '丹', '为', '主', '举', '久', '么', '义', '也', '了', '争', '事', '二', '于', '五', '亚', '亡', '京', '人', '什', '仍', '从', '仓', '他', '代', '以', '们', '件', '优', '会', '但', '何', '你', '使', '例', '信', '值', '偷', '傑', '傲', '光', '六', '兰', '共', '关', '兴', '兵', '其', '养', '军', '冰', '决', '况', '凯', '出', '分', '刘', '刚', '到', '制', '前', '力', '加', '务', '动', '勇', '北', '千', '华', '单', '博', '占', '印', '即', '历', '压', '去', '反', '发', '取', '受', '变', '口', '古', '只', '可', '史', '号', '合', '吉', '同', '名', '向', '否', '告', '和', '品', '哪', '唐', '喜', '嘴', '四', '因', '国', '图', '在', '基', '士', '复', '外', '多', '大', '天', '奋', '奥', '好', '如', '姻', '婚', '子', '孙', '学', '宁', '安', '定', '实', '害', '富', '察', '对', '导', '将', '少', '展', '属', '峡', '巍', '己', '已', '巴', '币', '市', '师', '希', '帝', '带', '平', '年', '并', '广', '应', '府', '度', '廉', '异', '张', '强', '律', '得', '心', '必', '志', '念', '怎', '情', '想', '意', '感', '愤', '愿', '成', '我', '或', '战', '所', '报', '抱', '持', '挟', '损', '换', '据', '接', '控', '提', '支', '改', '政', '教', '敦', '数', '整', '文', '新', '方', '族', '无', '日', '时', '春', '是', '晦', '更', '有', '服', '朗', '望', '本', '机', '杀', '杂', '权', '李', '来', '杨', '构', '林', '样', '核', '根', '格', '概', '榜', '欢', '欣', '欧', '歉', '死', '比', '毛', '毫', '民', '永', '求', '汇', '江', '没', '治', '波', '洲', '活', '济', '浦', '海', '淇', '淹', '清', '温', '港', '渴', '点', '热', '無', '焦', '然', '燕', '狗', '独', '王', '玥', '现', '理', '瑞', '生', '田', '由', '界', '登', '百', '的', '益', '盘', '直', '相', '真', '知', '示', '程', '稳', '立', '简', '管', '米', '类', '粑', '粪', '糍', '糯', '纲', '组', '织', '经', '统', '考', '者', '耻', '能', '自', '致', '舜', '良', '英', '葉', '蒙', '藏', '虑', '被', '西', '要', '观', '视', '觉', '解', '言', '认', '记', '许', '诉', '试', '该', '误', '说', '请', '读', '谁', '谢', '谣', '财', '货', '质', '贵', '跨', '车', '辉', '辰', '辱', '辽', '过', '运', '还', '这', '远', '迫', '透', '道', '那', '郎', '部', '都', '里', '重', '量', '金', '钱', '错', '问', '阅', '队', '际', '隆', '雄', '雅', '需', '青', '静', '非', '面', '韦', '韩', '韬', '顶', '预', '领', '题', '饼', '香', '骄', '高', '鰴', '鸣', '鸿', '黄', '黎', '黑', '龙', '\\ue00d', '\\ue044', '\\ue83a', '\\uf020', '\\uf021', '\\uf022', '\\uf025', '\\uf028', '\\uf02a', '\\uf02c', '\\uf02d', '\\uf02e', '\\uf02f', '\\uf038', '\\uf039', '\\uf04a', '\\uf06e', '\\uf075', '\\uf076', '\\uf078', '\\uf095', '\\uf0a4', '\\uf0a7', '\\uf0b0', '\\uf0b7', '\\uf0d6', '\\uf0f0', 'ﬀ', 'ﬁ', 'ﬂ', 'ﬃ', '\\ufeff', '＂', '（', '）', '，', '：', '？', 'Ｆ', 'Ｉ', 'Ｎ', 'Ｏ', 'Ｐ', 'Ｔ', 'ｏ', '￡', '�', '\\U000f1be0', '\\U000f1bec', '\\U000f1bfb', '\\U000f3ba0', '\\U000f4d25', '\\U000f6ca7', '\\U000fc924', '\\U000fc925', '\\U000fcaf2', '\\U000fcb2c', '\\U000fcd33', '\\U00100002', '\\U00100017', '\\U00100051', '\\U00100083', '\\U00100084']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dNLVfFBaP3Ox",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "int_to_vocab = {}\n",
        "for character, value in vocab_to_int.items():\n",
        "    int_to_vocab[value] = character"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O85KI69wzAPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "db9a3a75-4957-4f9d-fc11-99a597fd5876"
      },
      "cell_type": "code",
      "source": [
        "int_words = [vocab_to_int[word] for word in words]\n",
        "\n",
        "print(int_words[:30])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b3f3322cdd95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mint_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvocab_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-b3f3322cdd95>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mint_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvocab_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'as'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "hWKVUJc80k9c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**making batches**"
      ]
    },
    {
      "metadata": {
        "id": "9sLVy-Mbz5s0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**generating batches**"
      ]
    },
    {
      "metadata": {
        "id": "EcHmozQXtqj3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **building model**"
      ]
    },
    {
      "metadata": {
        "id": "9SRygBsxXMkm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_U_sP7GKXRJb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SkipGram(nn.Module):\n",
        "    def __init__(self, n_vocab, n_embed):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(n_vocab,n_embed)\n",
        "        self.output = nn.Linear(n_embed, n_vocab)\n",
        "        self.log_softmax=nn.LogSoftmax(dim=1)\n",
        "        \n",
        "        # complete this SkipGram model\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x=self.embed(x)\n",
        "        scores=self.output(x)\n",
        "        log_ps = self.log_softmax(scores)\n",
        "        # define the forward behavior\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xmSmQ7LT03lW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **training**"
      ]
    },
    {
      "metadata": {
        "id": "oIkK9f1IXYGP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check if GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "embedding_dim=300 #can be changed\n",
        "\n",
        "model = SkipGram(len(vocab_to_int), embedding_dim).to(device)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "print_every = 100\n",
        "steps = 0\n",
        "epochs = 5\n",
        "\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    \n",
        "    # get input and target batches\n",
        "    for inputs, targets in get_batches(train_words, 512):\n",
        "        steps += 1\n",
        "        inputs, targets = torch.LongTensor(inputs), torch.LongTensor(targets)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        \n",
        "        log_ps = model(inputs)\n",
        "        loss = criterion(log_ps, targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if steps % print_every == 0:                  \n",
        "            # getting examples and similarities      \n",
        "            valid_examples, valid_similarities = cosine_similarity(model.embed, device=device)\n",
        "            _, closest_idxs = valid_similarities.topk(6) # topk highest similarities\n",
        "            \n",
        "            valid_examples, closest_idxs = valid_examples.to('cpu'), closest_idxs.to('cpu')\n",
        "            for ii, valid_idx in enumerate(valid_examples):\n",
        "                closest_words = [int_to_vocab[idx.item()] for idx in closest_idxs[ii]][1:]\n",
        "                print(int_to_vocab[valid_idx.item()] + \" | \" + ', '.join(closest_words))\n",
        "            print(\"...\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gvz6Mcods4zM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **correcting spelling mistakes of input words**"
      ]
    },
    {
      "metadata": {
        "id": "eoAhCyw1s0ED",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def text_to_ints(text):\n",
        "    return [vocab_to_int[word] for word in text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jnQHMr5YvtSv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text = \"they are condisering their optons as the arleady\"\n",
        "text = text_to_ints(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ML14rf3yvuEh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pad = vocab_to_int[\"<PAD>\"] \n",
        "\n",
        "print('\\nText')\n",
        "print('  Word Ids:    {}'.format([i for i in text]))\n",
        "print('  Input Words: {}'.format(\"\".join([int_to_vocab[i] for i in text])))\n",
        "\n",
        "print('\\nSummary')\n",
        "print('  Word Ids:       {}'.format([i for i in answer_logits if i != pad]))\n",
        "print('  Response Words: {}'.format(\"\".join([int_to_vocab[i] for i in answer_logits if i != pad])))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}